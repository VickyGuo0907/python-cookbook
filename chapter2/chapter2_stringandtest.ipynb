{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter 2 Strings and Text\n",
    "\n",
    "Almost every useful program involves some kind of text processing, whether it is parsing data or generating output. This chapter focuses on common problems involving text manipulation, such as pulling apart strings, searching, substitution, lexing, and parsing. Many of these tasks can be easily solved using built-in methods of strings. However, more complicated operations might require the use of regular expressions or the cre‐ ation of a full-fledged parser. All of these topics are covered. In addition, a few tricky aspects of working with Unicode are addressed.\n",
    "\n",
    "## 2.1 Splitting Strings on Any of Multiple Delimiters\n",
    "The **split()** method of string objects is really meant for very simple cases, and does not allow for multiple delimiters or account for possible whitespace around the delim‐ iters. In cases when you need a bit more flexibility, use the **re.split()** method\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']\n['asdf', ' ', 'fjdk', ';', 'afed', ',', 'fjek', ',', 'asdf', ',', 'foo']\n['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']\n[' ', ';', ',', ',', ',', '']\n"
     ]
    }
   ],
   "source": [
    "line = 'asdf fjdk; afed, fjek, asdf,       foo'\n",
    "import re \n",
    "result = re.split(r'[;,\\s]\\s*', line)\n",
    "\n",
    "print(result)\n",
    "\n",
    "fields = re.split(r'(;|,|\\s)\\s*', line)\n",
    "print(fields)\n",
    "\n",
    "values = fields[::2]\n",
    "delimiters = fields[1::2] + ['']\n",
    "print(values)\n",
    "print(delimiters)"
   ]
  },
  {
   "source": [
    "## 2.2 Matching Text at the Start or End of a String\n",
    "A simple way to check the beginning or end of a string is to use the **str.startswith()** or **str.endswith()** methods. \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "file end with txt :  True\nfile start with : False\nurl start with http :  True\n"
     ]
    }
   ],
   "source": [
    "filename = 'spam.txt'\n",
    "print(\"file end with txt : \", filename.endswith('.txt'))\n",
    "\n",
    "print(\"file start with :\", filename.startswith('file:'))\n",
    "\n",
    "url = 'http://www.python.org'\n",
    "print(\"url start with http : \", url.startswith('http'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "all files with .h/.c :  ['foo.c', 'spam.c', 'spam.h']\nhave python file:  True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "filesname = os.listdir('.')\n",
    "filesname = ['Makefile', 'foo.c', 'bar.py', 'spam.c', 'spam.h']\n",
    "print(\"all files with .h/.c : \", [name for name in filesname if name.endswith(('.c','.h'))])\n",
    "print(\"have python file: \", any(name.endswith('.py') for name in filesname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "def read_data(name):\n",
    "    if names.startwith(('http:', 'https:', 'ftp:')):\n",
    "        return urlopen(name).read()\n",
    "    else:\n",
    "        with open(name) as f:\n",
    "            return f.read()\n",
    "choices = ['http:', 'ftp:']\n",
    "url = 'http://www.python.org'\n",
    "print(url.startswith(tuple(choices)))"
   ]
  },
  {
   "source": [
    "## 2.3 Matching Strings Using Shell Wildcard Pattern \n",
    "\n",
    "The **fnmatch** module provides two functions—**fnmatch()** and **fnmatchcase()**—that can be used to perform such matching."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nTrue\nTrue\n['Dat1.csv', 'Dat2.csv']\n"
     ]
    }
   ],
   "source": [
    "from fnmatch import fnmatch, fnmatchcase\n",
    "print(fnmatch('foo.txt', '*.txt'))\n",
    "\n",
    "print(fnmatch('foo.txt', '?oo.txt'))\n",
    "print(fnmatch('Dat45.csv', 'Dat[0-9]*'))\n",
    "\n",
    "names = ['Dat1.csv', 'Dat2.csv', 'config.ini', 'foo.py']\n",
    "\n",
    "print([name for name in names if fnmatch(name, 'Dat*.csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\nFalse\n"
     ]
    }
   ],
   "source": [
    "#  False on OS X (Mac), True on Windows\n",
    "\n",
    "print(fnmatch('foo.txt', '*.TXT')) # False on OS X (Mac), True on Windows\n",
    "\n",
    "# disctinction\n",
    "print(fnmatchcase('foo.txt', '*.TXT'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['5412 N CLARK ST', '1060 W ADDISON ST', '2122 N CLARK ST']\n['5412 N CLARK ST']\n"
     ]
    }
   ],
   "source": [
    "addresses = [\n",
    "        '5412 N CLARK ST',\n",
    "        '1060 W ADDISON ST',\n",
    "        '1039 W GRANVILLE AVE',\n",
    "        '2122 N CLARK ST',\n",
    "        '4802 N BROADWAY',\n",
    "]\n",
    "\n",
    "from fnmatch import fnmatch, fnmatchcase\n",
    "\n",
    "print([addr for addr in addresses if fnmatchcase(addr, '* ST')])\n",
    "print([addr for addr in addresses if fnmatchcase(addr, '54[0-9][0-9] *CLARK*')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.4 Matching and Searching for Text Pattern\n",
    "If the text you’re trying to match is a simple literal, you can often just use the basic string methods, \n",
    "such as **str.find()**, **str.endswith()**, **str.startswith()**, or similar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\nTrue\nFalse\n10\n"
     ]
    }
   ],
   "source": [
    "text = 'yeah, but no, but yeah, but no, but yeah'\n",
    "\n",
    "# Exact match \n",
    "print(text == 'yeah')\n",
    "\n",
    "# Match at start or end\n",
    "print(text.startswith('yeah'))\n",
    "print(text.endswith('no'))\n",
    "\n",
    "# Search for the location of the first occurrence\n",
    "print(text.find('no'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "yes\nno\nyes\nno\n['11/27/2012', '3/13/2013']\n"
     ]
    }
   ],
   "source": [
    "test1 = '11/27/2012'\n",
    "test2 = 'Nov 27,  2012'\n",
    "\n",
    "import re\n",
    "# Simple matching: \\d+ means match one or more digits\n",
    "if re.match(r'\\d+/\\d+/\\d+', test1):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n",
    "\n",
    "if re.match(r'\\d+/\\d+/\\d+', test2):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n",
    "\n",
    "datepat = re.compile(r'\\d+/\\d+/\\d+')\n",
    "if datepat.match(test1):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n",
    "\n",
    "if datepat.match(test2):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n",
    "\n",
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "print(datepat.findall(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<re.Match object; span=(0, 10), match='11/27/2012'>\n11/27/2012\n11\n27\n2012\n('11', '27', '2012')\n[('11', '27', '2012'), ('3', '13', '2013')]\n2012-11-27\n2013-3-13\n('11', '27', '2012')\n('3', '13', '2013')\n"
     ]
    }
   ],
   "source": [
    "datepat = re.compile(r'(\\d+)/(\\d+)/(\\d+)')\n",
    "m = datepat.match('11/27/2012')\n",
    "print(m)\n",
    "\n",
    "print(m.group(0))\n",
    "print(m.group(1))\n",
    "print(m.group(2))\n",
    "print(m.group(3))\n",
    "print(m.groups())\n",
    "\n",
    "month, day, year = m.groups()\n",
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "# Find all matches (notice splitting into tuples)\n",
    "print(datepat.findall(text))\n",
    "\n",
    "for month, day, year in datepat.findall(text):\n",
    "    print('{}-{}-{}'.format(year,month,day))\n",
    "\n",
    "for m in datepat.finditer(text):\n",
    "    print(m.groups())"
   ]
  },
  {
   "source": [
    "## 2.5 Searching and Replacing Text\n",
    "\n",
    "For simple literal patterns, use the **str.replace()** method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "yep, but no, but yep, but no, but yep\nToday is 2012-11-27. PyCon starts 2013-3-13.\nToday is 27 Nov 2012. PyCon starts 13 Mar 2013.\n"
     ]
    }
   ],
   "source": [
    "text = 'yeah, but no, but yeah, but no, but yeah'\n",
    "\n",
    "print(text.replace('yeah', 'yep'))\n",
    "\n",
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "import re\n",
    "print(re.sub(r'(\\d+)/(\\d+)/(\\d+)', r'\\3-\\1-\\2', text))\n",
    "\n",
    "from calendar import month_abbr\n",
    "\n",
    "def change_date(m):\n",
    "    mon_name = month_abbr[int(m.group(1))]\n",
    "    return '{} {} {}'.format(m.group(2), mon_name, m.group(3))\n",
    "\n",
    "print(datepat.sub(change_date, text))"
   ]
  },
  {
   "source": [
    "## 2.6 Searching and Replacing Case-Insensitive Text\n",
    "\n",
    "To perform case-insensitive text operations, you need to use the re module and supply the re.IGNORECASE flag to various operations.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['PYTHON', 'python', 'Python']\nUPPER snake, lower snake, Mixed snake\n"
     ]
    }
   ],
   "source": [
    "text = 'UPPER PYTHON, lower python, Mixed Python'\n",
    "\n",
    "print(re.findall('python', text, flags=re.IGNORECASE))\n",
    "print(re.sub('python','snake', text, flags=re.IGNORECASE))"
   ]
  },
  {
   "source": [
    "## 2.7 Specifying a Regular Expression for the Shortest Match\n",
    "\n",
    "This problem often arises in patterns that try to match text enclosed inside a pair of starting and ending delimiters (e.g., a quoted string)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['no.']\n['no.\" Phone says \"yes.']\n['no.', 'yes.']\n"
     ]
    }
   ],
   "source": [
    "str_pat = re.compile(r'\\\"(.*)\\\"')\n",
    "text1 = 'Computer say \"no.\"'\n",
    "print(str_pat.findall(text1))\n",
    "\n",
    "text2 = 'Computer say \"no.\" Phone says \"yes.\"'\n",
    "print(str_pat.findall(text2))\n",
    "\n",
    "str_pat = re.compile(r'\\\"(.*?)\\\"')\n",
    "print(str_pat.findall(text2))"
   ]
  },
  {
   "source": [
    "## 2.8 Writing a Regular Expression for Multiline Patterns\n",
    "\n",
    "This problem typically arises in patterns that use the dot (.) to match any character but forget to account for the fact that it doesn’t match newlines."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[' this is a comment ']\n[]\n[' this is a\\n              multiline comment ']\n[' this is a\\n              multiline comment ']\n"
     ]
    }
   ],
   "source": [
    "comment = re.compile(r'/\\*(.*?)\\*/')\n",
    "text1 = '/* this is a comment */'\n",
    "text2 = '''/* this is a\n",
    "              multiline comment */'''\n",
    "print(comment.findall(text1))\n",
    "print(comment.findall(text2))\n",
    "\n",
    "comment = re.compile(r'/\\*((?:.|\\n)*?)\\*/')\n",
    "print(comment.findall(text2))\n",
    "\n",
    "comment = re.compile(r'/\\*(.*?)\\*/', re.DOTALL)\n",
    "print(comment.findall(text2))"
   ]
  },
  {
   "source": [
    "## 2.9 Normalizing Unicode Text to a Standard Representation \n",
    "\n",
    "In Unicode, certain characters can be represented by more than one valid sequence of code points. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Spicy Jalapeño\nSpicy Jalapeño\nFalse\n14\n15\n"
     ]
    }
   ],
   "source": [
    "s1 = 'Spicy Jalape\\u00f1o'\n",
    "s2 = 'Spicy Jalapen\\u0303o'\n",
    "\n",
    "print(s1)\n",
    "print(s2)\n",
    "print(s1 == s2)\n",
    "print(len(s1))\n",
    "print(len(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n'Spicy Jalape\\xf1o'\nTrue\n'Spicy Jalapen\\u0303o'\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "# NFC means that characters should be fully composed\n",
    "t1 = unicodedata.normalize('NFC', s1)\n",
    "t2 = unicodedata.normalize('NFC', s2)\n",
    "\n",
    "print(t1 == t2)\n",
    "print(ascii(t1))\n",
    "\n",
    "# NFD means that characters should be fully decomposed with the use of combining char‐ acters.\n",
    "t3 = unicodedata.normalize('NFD', s1)\n",
    "t4 = unicodedata.normalize('NFD', s2)\n",
    "\n",
    "print(t3 == t4)\n",
    "print(ascii(t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ﬁ\nﬁ\nfi\nfi\nSpicy Jalapeno\n"
     ]
    }
   ],
   "source": [
    "s = '\\ufb01'\n",
    "\n",
    "print(s)\n",
    "print(unicodedata.normalize('NFD',s))\n",
    "\n",
    "# Notice how the combined letters are broken apart here\n",
    "print(unicodedata.normalize('NFKD', s))\n",
    "\n",
    "print(unicodedata.normalize('NFKC', s))\n",
    "\n",
    "t1 = unicodedata.normalize('NFD', s1)\n",
    "print(''.join(c for c in t1 if not unicodedata.combining(c)))"
   ]
  },
  {
   "source": [
    "## 2.10 Working with Unicode Characters in Regular Expressions\n",
    "\n",
    "By default, the re module is already programmed with rudimentary knowledge of cer‐ tain Unicode character classes.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<re.Match object; span=(0, 3), match='123'>\n<re.Match object; span=(0, 3), match='١٢٣'>\n<re.Match object; span=(0, 6), match='straße'>\nNone\nSTRASSE\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "num = re.compile('\\d+')\n",
    "# ASCII digits\n",
    "print(num.match('123'))\n",
    "\n",
    "# Arabic digits\n",
    "print(num.match('\\u0661\\u0662\\u0663'))\n",
    "\n",
    "pat = re.compile('stra\\u00dfe', re.IGNORECASE)\n",
    "s = 'straße'\n",
    "print(pat.match(s))  # Matches\n",
    "print(pat.match(s.upper())) # Doesn't match\n",
    "\n",
    "print(s.upper())  # Case folds\n"
   ]
  },
  {
   "source": [
    "## 2.11 Stripping Unwanted Characters from Strings\n",
    "\n",
    "The **strip()** method can be used to strip characters from the beginning or end of a string. **lstrip()** and **rstrip()** perform stripping from the left or right side, respectively. By default, these methods strip whitespace, but other characters can be given.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hello world\nhello world   \n\n   hello world\nhello=====\nhello\nhelloworld\n\n hello world \n"
     ]
    }
   ],
   "source": [
    "# Whitespace stripping\n",
    "s = '   hello world   \\n'\n",
    "\n",
    "print(s.strip())\n",
    "print(s.lstrip())\n",
    "print(s.rstrip())\n",
    "\n",
    "# Character stripping\n",
    "t = '-----hello====='\n",
    "print(t.lstrip('-'))\n",
    "print(t.strip('-='))\n",
    "\n",
    "s = '  hello     world   \\n'\n",
    "\n",
    "print(s.replace(' ', ''))\n",
    "\n",
    "import re \n",
    "print(re.sub('\\s+', ' ', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pýtĥöñ\fis\tawesome\n\npýtĥöñ is awesome\n\npython is awesome\n\n"
     ]
    }
   ],
   "source": [
    "## 2.12 Sanitizing and Cleaning Up Text \n",
    "\n",
    "s = 'pýtĥöñ\\fis\\tawesome\\r\\n'\n",
    "print(s)\n",
    "\n",
    "remap = {\n",
    "    ord('\\t'): ' ',\n",
    "    ord('\\f'): ' ',\n",
    "    ord('\\r'): None    # Deleted\n",
    "}\n",
    "\n",
    "a = s.translate(remap)\n",
    "print(a)\n",
    "\n",
    "b = unicodedata.normalize('NFD', a)\n",
    "print(b.encode('ascii', 'ignore').decode('ascii'))\n",
    "\n",
    "# fast apprach to clean up whitespace\n",
    "def clean_space(s):\n",
    "    s = s.replace('\\r', '')\n",
    "    s = s.replace('\\t', ' ')\n",
    "    s = s.replace('\\f', ' ')\n",
    "    return s\n"
   ]
  },
  {
   "source": [
    "## 2.13 Aligning Text Strings\n",
    "\n",
    "For basic alignment of strings, the **ljust()**, **rjust()**, and **center()** methods of strings can be used. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hello World         \n         Hello World\n    Hello World     \n=========Hello World\n****Hello World*****\n         Hello World\nHello World         \n    Hello World     \n=========Hello World\n****Hello World*****\n"
     ]
    }
   ],
   "source": [
    "text = 'Hello World'\n",
    "print(text.ljust(20))\n",
    "\n",
    "print(text.rjust(20))\n",
    "\n",
    "print(text.center(20))\n",
    "\n",
    "print(text.rjust(20, '='))\n",
    "\n",
    "print(text.center(20, '*'))\n",
    "\n",
    "print(format(text, '>20'))\n",
    "\n",
    "print(format(text, '<20'))\n",
    "\n",
    "print(format(text,'^20'))\n",
    "\n",
    "print(format(text, '=>20s'))\n",
    "\n",
    "print(format(text, '*^20s'))"
   ]
  },
  {
   "source": [
    "## 2.14 Combining and Concatenating Strings\n",
    "\n",
    "If the strings you wish to combine are found in a sequence or iterable, the fastest way to combine them is to use the **join()** method. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Is Chicago Not Chicago?\nIs,Chicago,Not,Chicago?\nIsChicagoNotChicago?\nIs Chicago Not Chicago?\nACME,50,91.1\n"
     ]
    }
   ],
   "source": [
    "parts = ['Is', 'Chicago', 'Not', 'Chicago?']\n",
    "\n",
    "print(' '.join(parts))\n",
    "print(','.join(parts))\n",
    "print(''.join(parts))\n",
    "\n",
    "a = 'Is Chicago'\n",
    "b = 'Not Chicago?'\n",
    "print('{} {}'.format(a, b))\n",
    "\n",
    "data = ['ACME', 50, 91.1]\n",
    "print(','.join(str(d) for d in data))"
   ]
  },
  {
   "source": [
    "## 2.15 Interpolating Variables in Strings\n",
    "\n",
    "Python has no direct support for simply substituting variable values in strings. However, this feature can be approximated using the **format()** method of strings."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Guido has 37 messages.\nGuido has 37 messages.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Guido has 37 messages.'"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "s = '{name} has {n} messages.'\n",
    "print(s.format(name='Guido', n = 37))\n",
    "\n",
    "name = 'Guido'\n",
    "n = 37\n",
    "\n",
    "print(s.format_map(vars()))\n",
    "\n",
    "class Info:\n",
    "    def __init__(self, name, n):\n",
    "        self.name = name\n",
    "        self.n = n\n",
    "a = Info('Guido', 37)\n",
    "s.format_map(vars(a))"
   ]
  },
  {
   "source": [
    "## 2.16 Reformatting Text to a Fixed Number of Columns\n",
    "\n",
    "Use the textwrap module to reformat text for output."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Look into my eyes, look into my eyes, the eyes, the eyes, \\ the eyes,\nnot around the eyes, don't look around the eyes, \\ look into my eyes,\nyou're under.\nLook into my eyes, look into my eyes,\nthe eyes, the eyes, \\ the eyes, not\naround the eyes, don't look around the\neyes, \\ look into my eyes, you're under.\n   Look into my eyes, look into my eyes,\nthe eyes, the eyes, \\ the eyes, not\naround the eyes, don't look around the\neyes, \\ look into my eyes, you're under.\nLook into my eyes, look into my eyes,\n   the eyes, the eyes, \\ the eyes, not\n   around the eyes, don't look around\n   the eyes, \\ look into my eyes, you're\n   under.\n"
     ]
    }
   ],
   "source": [
    "s = \"Look into my eyes, look into my eyes, the eyes, the eyes, \\ the eyes, not around the eyes, don't look around the eyes, \\ look into my eyes, you're under.\"\n",
    "\n",
    "import textwrap\n",
    "\n",
    "print(textwrap.fill(s, 70))\n",
    "print(textwrap.fill(s, 40))\n",
    "\n",
    "print(textwrap.fill(s, 40, initial_indent='   '))\n",
    "\n",
    "print(textwrap.fill(s, 40, subsequent_indent='   '))"
   ]
  },
  {
   "source": [
    "## 2.17 Handling HTML and XML Entities in Text\n",
    "If you are producing text, replacing special characters such as < or > is relatively easy if you use the **html.escape()** function. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Elements are written as \"<tag>text</tag>\".\nElements are written as &quot;&lt;tag&gt;text&lt;/tag&gt;&quot;.\nElements are written as \"&lt;tag&gt;text&lt;/tag&gt;\".\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'The prompt is >>>'"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "s = 'Elements are written as \"<tag>text</tag>\".'\n",
    "\n",
    "import html\n",
    "print(s)\n",
    "\n",
    "print(html.escape(s))\n",
    "# Disable escaping of quotes\n",
    "print(html.escape(s, quote=False))\n",
    "\n",
    "s = 'Spicy &quot;Jalape&#241;o&quot.'\n",
    "from html.parser import HTMLParser\n",
    "p = HTMLParser()\n",
    "p.unescape(s)\n",
    "\n",
    "t = 'The prompt is &gt;&gt;&gt;'\n",
    "from xml.sax.saxutils import unescape\n",
    "unescape(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.18 Tokenizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Token(type='NAME', value='foo')\nToken(type='WS', value=' ')\nToken(type='EQ', value='=')\nToken(type='WS', value=' ')\nToken(type='NUM', value='42')\n"
     ]
    }
   ],
   "source": [
    "tokens = [('NAME', 'foo'), ('EQ','='), ('NUM', '23'), ('PLUS','+'),\n",
    "              ('NUM', '42'), ('TIMES', '*'), ('NUM', '10')]\n",
    "\n",
    "import re\n",
    "NAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)' \n",
    "NUM = r'(?P<NUM>\\d+)'\n",
    "PLUS = r'(?P<PLUS>\\+)'\n",
    "TIMES = r'(?P<TIMES>\\*)'\n",
    "EQ = r'(?P<EQ>=)'\n",
    "WS = r'(?P<WS>\\s+)'\n",
    "master_pat = re.compile('|'.join([NAME, NUM, PLUS, TIMES, EQ, WS]))\n",
    "\n",
    "scanner = master_pat.scanner('foo = 42')\n",
    "scanner.match()\n",
    "\n",
    "\n",
    "\n",
    "from collections import namedtuple\n",
    "Token = namedtuple('Token', ['type', 'value'])\n",
    "\n",
    "def generate_tokens(pat, text):\n",
    "    scanner = pat.scanner(text)\n",
    "    for m in iter(scanner.match, None):\n",
    "        yield Token(m.lastgroup, m.group())\n",
    "\n",
    "\n",
    "for tok in generate_tokens(master_pat, 'foo = 42'):\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.19 Writing a Simple Recursive Descent Parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "<module '__main__'> is a built-in module",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d171449fb41a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Build the lexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mlexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Grammar rules and handler functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ply/lex.py\u001b[0m in \u001b[0;36mlex\u001b[0;34m(module, object, debug, optimize, lextab, reflags, nowarn, outputdir, debuglog, errorlog)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0mlinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mSyntaxError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't build lexer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ply/lex.py\u001b[0m in \u001b[0;36mvalidate_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_literals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ply/lex.py\u001b[0m in \u001b[0;36mvalidate_rules\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0;31m# -----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ply/lex.py\u001b[0m in \u001b[0;36mvalidate_module\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m             \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsourcelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36mgetsourcelines\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    965\u001b[0m     raised if the source code cannot be retrieved.\"\"\"\n\u001b[1;32m    966\u001b[0m     \u001b[0mobject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m     \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mistraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    778\u001b[0m     is raised if the source code cannot be retrieved.\"\"\"\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;31m# Invalidate cache if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mno\u001b[0m \u001b[0mway\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0midentified\u001b[0m \u001b[0mto\u001b[0m \u001b[0mget\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \"\"\"\n\u001b[0;32m--> 696\u001b[0;31m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m     \u001b[0mall_bytecode_suffixes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachinery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG_BYTECODE_SUFFIXES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mall_bytecode_suffixes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachinery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZED_BYTECODE_SUFFIXES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36mgetfile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__file__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{!r} is a built-in module'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__module__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: <module '__main__'> is a built-in module"
     ]
    }
   ],
   "source": [
    "from ply.lex import lex\n",
    "from ply.yacc import yacc\n",
    "\n",
    "# Token list\n",
    "tokens = [ 'NUM', 'PLUS', 'MINUS', 'TIMES', 'DIVIDE', 'LPAREN', 'RPAREN' ]\n",
    "\n",
    "# Ignored characters\n",
    "t_ignore = ' \\t\\n'\n",
    "\n",
    "# Token specifications (as regexs)\n",
    "t_PLUS   = r'\\+'\n",
    "t_MINUS  = r'-'\n",
    "t_TIMES  = r'\\*'\n",
    "t_DIVIDE = r'/'\n",
    "t_LPAREN = r'\\('\n",
    "t_RPAREN = r'\\)'\n",
    "\n",
    "# Token processing functions\n",
    "def t_NUM(t): \n",
    "    r'\\d+'\n",
    "    t.value = int(t.value) \n",
    "    return t\n",
    "\n",
    "# Error handler\n",
    "def t_error(t):\n",
    "    print('Bad character: {!r}'.format(t.value[0])) \n",
    "    t.skip(1)\n",
    "\n",
    "# Build the lexer\n",
    "lexer = lex()\n",
    "\n",
    "# Grammar rules and handler functions\n",
    "def p_expr(p): \n",
    "    '''\n",
    "    expr : expr PLUS term\n",
    "         | expr MINUS term\n",
    "    '''\n",
    "    if p[2] == '+':\n",
    "        p[0] = p[1] + p[3]\n",
    "    elif p[2] == '-':\n",
    "        p[0] = p[1] - p[3]\n",
    "\n",
    "def p_expr_term(p): \n",
    "    '''\n",
    "    expr : term \n",
    "    '''\n",
    "    p[0] = p[1]\n",
    "\n",
    "\n",
    "def p_term(p): \n",
    "    '''\n",
    "    term : term TIMES factor\n",
    "         | term DIVIDE factor\n",
    "    '''\n",
    "    if p[2] == '*':\n",
    "        p[0] = p[1] * p[3]\n",
    "    elif p[2] == '/':\n",
    "        p[0] = p[1] / p[3]\n",
    "\n",
    "def p_term_factor(p): \n",
    "    '''\n",
    "    term : factor \n",
    "    '''\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_factor(p): \n",
    "    '''\n",
    "    factor : NUM\n",
    "    '''\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_factor_group(p): \n",
    "    '''\n",
    "    factor : LPAREN expr RPAREN \n",
    "    '''\n",
    "    p[0] = p[2]\n",
    "\n",
    "def p_error(p): \n",
    "    print('Syntax error')\n",
    "\n",
    "parser = yacc()\n",
    "\n",
    "print(parser.parser('2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.20 Performaing Text Operations on Byte Strings\n",
    "\n",
    "Byte strings already support most of the same built-in operations as text strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b'Hello'\nTrue\n[b'Hello', b'World']\nbytearray(b'Hello')\nTrue\n[bytearray(b'Hello'), bytearray(b'World')]\nHello World\n"
     ]
    }
   ],
   "source": [
    "data = b'Hello World'\n",
    "print(data[0:5])\n",
    "print(data.startswith(b'Hello'))\n",
    "print(data.split())\n",
    "data.replace(b'Hello', b'Hello Cruel')\n",
    "\n",
    "## byte arrays\n",
    "data = bytearray(b'Hello World')\n",
    "print(data[0:5])\n",
    "print(data.startswith(b'Hello'))\n",
    "print(data.split())\n",
    "data.replace(b'Hello', b'Hello Cruel')\n",
    "\n",
    "# regular expression\n",
    "data = b'FOO:BAR,SPAM'\n",
    "import re\n",
    "re.split(b'[:,]', data)\n",
    "\n",
    "s = b'Hello World'\n",
    "print(s.decode('ascii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}